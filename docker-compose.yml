name: llm-platform

services:
  # Frontend Service
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: llm-platform-frontend
    ports:
      - "${FRONTEND_PORT:-80}:80"
    depends_on:
      backend:
        condition: service_started
    networks:
      - llm-platform-network
    restart: unless-stopped

  # Backend Service
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: llm-platform-backend
    ports:
      - "${BACKEND_PORT:-8080}:8080"
    environment:
      - MYSQL_HOST=mysql
      - MYSQL_PORT=3306
      - MYSQL_DATABASE=${MYSQL_DATABASE:-llm_learning}
      - MYSQL_USERNAME=${MYSQL_USERNAME:-llm_user}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD:-llm_password}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - JWT_SECRET=${JWT_SECRET:-llm-language-learning-platform-secret-key-2024}
      - AI_DEFAULT_PROVIDER=${AI_DEFAULT_PROVIDER:-deepseek}
      - DEEPSEEK_ENABLED=${DEEPSEEK_ENABLED:-true}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY:-}
      - DEEPSEEK_BASE_URL=${DEEPSEEK_BASE_URL:-https://api.deepseek.com/v1}
      - DEEPSEEK_MODEL=${DEEPSEEK_MODEL:-deepseek-chat}
      - OPENAI_ENABLED=${OPENAI_ENABLED:-false}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-3.5-turbo}
      - OLLAMA_ENABLED=${OLLAMA_ENABLED:-false}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-qwen2.5:7b}
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - llm-platform-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:8080/api/auth/test > /dev/null"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s


  # MySQL Database
  mysql:
    image: mysql:8.0
    container_name: llm-platform-mysql
    ports:
      - "${MYSQL_PORT:-3306}:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD:-root_password}
      - MYSQL_DATABASE=${MYSQL_DATABASE:-llm_learning}
      - MYSQL_USER=${MYSQL_USERNAME:-llm_user}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD:-llm_password}
    volumes:
      - mysql-data:/var/lib/mysql
      - ./backend/src/main/resources/db/schema.sql:/docker-entrypoint-initdb.d/01-schema.sql:ro
    networks:
      - llm-platform-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD:-root_password}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    command: --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: llm-platform-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis-data:/data
    networks:
      - llm-platform-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    command: redis-server --appendonly yes

  # Ollama AI Service (Optional)
  ollama:
    image: ollama/ollama:latest
    container_name: llm-platform-ollama
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - llm-platform-network
    restart: unless-stopped
    profiles:
      - with-ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

# Networks
networks:
  llm-platform-network:
    driver: bridge

# Volumes
volumes:
  mysql-data:
    driver: local
  redis-data:
    driver: local
  ollama-data:
    driver: local
